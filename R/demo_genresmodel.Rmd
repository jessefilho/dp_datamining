---
title: "Genre DEMO"
output: html_notebook
---

This is the demo for solve Genre problematic. In order to well understand it, this file was resumed to only show up the data partition and model test.

About this set:
- Multi labels;
- Not discrete values;
- 


Main goal of this model:
- Classify new instances using these models;

Strategies:
- Find the must importantes features;
- Find the best model possible;
- Apply Supervised Classi fication;


Considerations:

- "Others" contains among genres known, anothers genres do not categorized.
- 


Vocabulary:

"discrete values" : ( Binary values like 0/1, yes/no, true/false )

'formula' : 

The variable on the left-hand side of a tilde (~) is called the "dependent variable"("response variable", "outcome variable" or "label"), while the variables on the right-hand side are called the "independent variables" ("predictor (variable)", "controlled variable", "feature") and are joined by plus signs +.

"+" : for adding terms;
"-" : for removing terms;

```{r}
#Load data
genres = read.csv(file = '~/Documents/dp_datamining/data/dataGenre.csv', header = TRUE, na.strings = "?")

#Data Preparation 
#Remove lyrics from this set
#genres$titlesong <- NULL
#Remove "tempo equals 0, because is not relevante for now."
genres <- genres[!genres$tempo <= 45.0 & !genres$tempo >= 250.0,]
#Remove "Others from type of group, because is not relevante now."
genres <- genres[!genres$typegroup == "Others",]

# genres$Class[genres$genretype=='Others'] <- 'NotHaveGenre'
# genres$Class[genres$genretype=='Rock'] <- 'hasGenre'
# genres$Class[genres$genretype=='Pop'] <- 'hasGenre'
# genres$Class[genres$genretype=='Hip Hop'] <- 'hasGenre'
# genres$Class[genres$genretype=='Jazz'] <- 'hasGenre'
# genres$Class[genres$genretype=='Funk'] <- 'hasGenre'
# genres$Class[genres$genretype=='Folk'] <- 'hasGenre'
# genres$Class[genres$genretype=='Classical'] <- 'hasGenre'
# genres$Class[genres$genretype=='Blues'] <- 'hasGenre'
# genres$Class[genres$genretype=='Country'] <- 'hasGenre'
# genres$Class[genres$genretype=='Electronic'] <- 'hasGenre'

#Create variables of genres
# genres$Others[genres$genretype=='Others'] <- 1
# genres$Others[genres$genretype!='Others'] <- 0
# 
# genres$Rock[genres$genretype=='Rock'] <- 1
# genres$Rock[genres$genretype!='Rock'] <- 0
# 
# genres$Pop[genres$genretype=='Pop'] <- 1
# genres$Pop[genres$genretype!='Pop'] <- 0
# 
# genres$Electronic[genres$genretype=='Electronic'] <- 1
# genres$Electronic[genres$genretype!='Electronic'] <- 0
# 
# genres$HipHop[genres$genretype=='Hip Hop'] <- 1
# genres$HipHop[genres$genretype!='Hip Hop'] <- 0
# 
# genres$Jazz[genres$genretype=='Jazz'] <- 1
# genres$Jazz[genres$genretype!='Jazz'] <- 0
# 
# genres$Funk[genres$genretype=='Funk'] <- 1
# genres$Funk[genres$genretype!='Funk'] <- 0
# 
# genres$Folk[genres$genretype=='Folk'] <- 1
# genres$Folk[genres$genretype!='Folk'] <- 0
# 
# genres$Classical[genres$genretype=='Classical'] <- 1
# genres$Classical[genres$genretype!='Classical'] <- 0
# 
# genres$Country[genres$genretype=='Country'] <- 1
# genres$Country[genres$genretype!='Country'] <- 0
# 
# genres$Blues[genres$genretype=='Blues'] <- 1
# genres$Blues[genres$genretype!='Blues'] <- 0



summary(genres$genretype)

summary(genres)
```

Steps to prepare data for the Classfication Model:
1. Reduction of the dataset of "Others" for take a proportion;
2. If necessary viabilization of a set for a 3th test


```{r}
library(dplyr)
library(quadprog)
#take a sample of genres "Others"
#Only 2% from attributes with the label Others
idx_others <- genres[sample(which(genres$genretype=='Others'),size = 0.02* nrow(genres[which(genres$genretype=='Others'),]) ), ]
#dataset without the label Others
dataset_withoutOthers <- genres[!genres$genretype=='Others',]
#Reattach A small and random data set with Others
genres_ToSplit <- bind_rows(idx_others,dataset_withoutOthers)

summary(genres_ToSplit)
```



2. Split data in 2 dataset:
2.1 Train
2.2 Test

```{r}
# Split between 80 and 30
index <- sample(1:nrow(genres_ToSplit),size = 0.7* nrow(genres_ToSplit))
# Use the large partition to training - 70
train <- genres_ToSplit[index,]
# Use the small partition to test - 30
test <- genres_ToSplit[-index,]
```

```{r}
train[,14:23]
```

```{r}
summary(train)
summary(train$genretype)
```

```{r}
summary(test)
summary(test$genretype)
```


```{r}
# histogram of genre frequencies
par(mai=c(1,1.5,1,1))
barplot(sort(colSums(train[,14:23]), decreasing = FALSE), 
        horiz = TRUE, cex.names = 1, col = 'springgreen4', 
        main = 'Genre Frequency of Train Set', las = 1)

# histogram of genre frequencies
par(mai=c(1,1.5,1,1))
barplot(sort(colSums(test[,14:23]), decreasing = FALSE), 
        horiz = TRUE, cex.names = 1, col = 'blue', 
        main = 'Genre Frequency of Test Set', las = 1)
```

```{r}
print(train[,3:11])
```

Comparing caret package algorithms:
a) nb
b) knn
c) SVM Radial

```{r}
library(caret)
library(ggplot2)
library(rpart.plot)
library(klaR)

# Run algorithms using 10-fold cross validation
control <- trainControl(method="cv", number=10)
metric <- "Accuracy"
formula <- genretype ~ -tempo-energy-danceability-speechiness+accoustiness+loudness-duration+valence-instrumentalness

# a) nb 
set.seed(7)
fit.nb_train <- train(formula, data = train, method = "nb", metric=metric, trControl=control)

# b) knn 
set.seed(7)
fit.knn_train <- train(formula, data = train, method = "knn", metric=metric, trControl=control)

# c) SVM Radial 
set.seed(7)
fit.svmRadial_train <- train(formula, data = train, method = "svmRadial", metric=metric, trControl=control)

# estimate variable importance
importance <- varImp(fit.knn_train, scale=FALSE)
# summarize importance
print(importance)
# plot importance
plot(importance)

# summarize accuracy of models
results <- resamples(list(nb=fit.nb_train, 
                          knn=fit.knn_train,
                          svmRadial=fit.svmRadial_train))
summary(results)

# compare accuracy of models
dotplot(results)


```

Build the first classfication model with set of train Decision Tree;

Trying find the combination of features:
a) all
b) loudness, valence, accoustiness


```{r}
library(rpart)
library(rpart.plot)
#Build the first classfication model
#to using the command rpat, R will build a tree where Class is to be predicted from the variable presents at the formula

#Model classfication of train
#Rock+tempo+energy+danceability+speechiness+accoustiness+loudness+loudness+duration+valence+instrumentalness
set.seed(7)
formula_treeD <- genretype~ +tempo+energy+danceability+speechiness+accoustiness+loudness-duration+valence+instrumentalness
fit.tree_train = rpart(formula_treeD, data = train, method = "class")

#Plotting the tree of train
plot(fit.tree_train, compress=TRUE, uniform=TRUE)
text(fit.tree_train,use.n = T,all=T,cex=.7, pretty=0, xpd=TRUE, digits = 6)
prp(fit.tree_train, extra=101)
# Visualize the decision tree with rpart.plot
rpart.plot(fit.tree_train, box.palette="RdBu", shadow.col="gray", nn=TRUE)
#Test errors of train tree
pred <- predict(fit.tree_train, train, type = "class")
mConfusion <- table(train$genretype, pred)
print(mConfusion)

#Test Accuracy of model
acc <- (mConfusion[1,1]+mConfusion[2,2])/sum(mConfusion)
print("acc")
print(acc*100)

#Compute error rate
Err <- (mConfusion[1,2]+mConfusion[2,1])/sum(mConfusion)
print("err")
print(Err*100)
```

```{r}
summary(train)
```


```{r}
library(rpart)
library(rpart.plot)
#Build the first classfication model
#to using the command rpat, R will build a tree where Class is to be predicted from the variable presents at the formula

#Model classfication of train
#Rock+tempo+energy+danceability+speechiness+accoustiness+loudness+loudness+duration+valence+instrumentalness
set.seed(7)
lvaFormula = Class ~ +loudness+valence+accoustiness

trainTree_Rock = rpart(lvaFormula, data = train, method = "class")

#Plotting the tree of train
plot(trainTree_Rock, compress=TRUE, uniform=TRUE)
text(trainTree_Rock,use.n = T,all=T,cex=.7, pretty=0, xpd=TRUE, digits = 6)
prp(trainTree_Rock, extra=101)
# Visualize the decision tree with rpart.plot
rpart.plot(trainTree_Rock, box.palette="RdBu", shadow.col="gray", nn=TRUE)
#Test errors of train tree
pred <- predict(trainTree_Rock, train, type = "class")
mConfusion <- table(train$Class, pred)
print(mConfusion)

#Test Accuracy of model
acc <- (mConfusion[1,1]+mConfusion[2,2])/sum(mConfusion)
print("acc")
print(acc*100)

#Compute error rate
Err <- (mConfusion[1,2]+mConfusion[2,1])/sum(mConfusion)
print("err")
print(Err*100)


```

Test best formula:

```{r}
library(rpart)
#Errors array
errors <- numeric(0)
#Accuracies array
accs <- numeric(0)
#Randomly shuffle the data
yourdata<-genres_ToSplit[sample(nrow(genres_ToSplit)),]
#Create 10 equally size folds
folds <- cut(seq(1,nrow(yourdata)),breaks=10,labels=FALSE)
#Perform 10 fold cross validation
validationFormula <- lvaFormula
for(i in 1:10){
  #Segement your data by fold using the which() function 
  testIndexes <- which(folds==i,arr.ind=TRUE)
  testData <- yourdata[testIndexes, ]
  trainData <- yourdata[-testIndexes, ]
  #Use the test and train data partitions however you desire...
  
  #Model classfication of train
  trainTree = rpart(validationFormula, data = trainData, method = "class")
  
  #Plotting the tree of train
  #plot(trainTree_Rock, compress=TRUE, uniform=TRUE)
  #text(trainTree_Rock,use.n = T,all=T,cex=.7, pretty=0, xpd=TRUE, digits = 6)
  #prp(trainTree_Rock, extra=101)

  
  pred <- predict(trainTree, trainData, type = "class")
  mConfusion <- table(trainData$Class, pred)
  
  #Test Accuracy of model
  acc <- (mConfusion[1,1]+mConfusion[2,2])/sum(mConfusion)
  #print("acc")
  #print(acc*100)
  
  #Compute error rate
  Err <- (mConfusion[1,2]+mConfusion[2,1])/sum(mConfusion)
  #print("err")
  #print(Err*100)
  
  accs <- rbind(accs,acc)
  errors <- rbind(errors,Err)
}
```

Accuracy
Accuracy (ACC) is calculated as the number of all correct predictions divided by the total number of the dataset. The best accuracy is 1.0, whereas the worst is 0.0. It can also be calculated by 1 – ERR.


Error rate
Error rate (ERR) is calculated as the number of all incorrect predictions divided by the total number of the dataset. The best error rate is 0.0, whereas the worst is 1.0.




```{r}
meanAcc <- mean(accs)
meanError <- mean(errors)
print("Acc mean: ")
print(meanAcc)
print("Err mean: ")
print(meanError)
```

The result are strong related with song features than with quantity of genrer classfied, it occours because some genre can have common features, only changing one specific feature.

Reference:
https://musicmap.info/



- Nayve Bayes
```{r}
#Construction of q naive Bayes classifier

#Getting started with Naive Bayes
#Install the package
#install.packages(“e1071”)
#Loading the library
library(e1071)
#Randomly shuffle the data
data_nb<-genres_ToSplit[sample(nrow(genres_ToSplit)),]
#summary(data_nb)
#Create 10 equally size folds
folds_nb <- cut(seq(1,nrow(data_nb)),breaks=10,labels=FALSE)
#Perform 10 fold cross validation
#Segement your data by fold using the which() function 
testIndexes <- which(folds_nb==i,arr.ind=TRUE)
testData <- data_nb[testIndexes, ]
trainData <- data_nb[-testIndexes, ]
val_nbFormula <- Rock~.
#Fitting the Naive Bayes model
Naive_Bayes_Model=naiveBayes(val_nbFormula, data=trainData)
#What does the model say? Print the model summary
#Naive_Bayes_Model

pred_nb_train <- predict(Naive_Bayes_Model, trainData)
mConfusion <- table(trainData$Rock,pred_nb_train)
print(mConfusion)
#Test Accuracy of model
acc <- (mConfusion[1,1]+mConfusion[2,2])/sum(mConfusion)
#print("acc")
#print(acc*100)

#Compute error rate
Err <- (mConfusion[1,2]+mConfusion[2,1])/sum(mConfusion)
#print("err")
#print(Err*100)

accs <- rbind(accs,acc)
errors <- rbind(errors,Err)
  

meanAcc <- mean(accs)
meanError <- mean(errors)
print("Acc mean: ")
print(meanAcc)
print("Err mean: ")
print(meanError)


```

```{r}
library(e1071)
#Errors array
errors <- numeric(0)
#Accuracies array
accs <- numeric(0)
#Randomly shuffle the data
yourdata<-genres_ToSplit[sample(nrow(genres_ToSplit)),]
#Create 10 equally size folds
folds <- cut(seq(1,nrow(yourdata)),breaks=10,labels=FALSE)
#Perform 10 fold cross validation
for(i in 1:10){
  #Segement your data by fold using the which() function 
  testIndexes <- which(folds==i,arr.ind=TRUE)
  testData <- yourdata[testIndexes, ]
  trainData <- yourdata[-testIndexes, ]
  #Use the test and train data partitions however you desire...
  #Rock~ Rock+tempo+energy+danceability+speechiness+accoustiness+loudness+loudness+duration+valence+instrumentalness
  #Fitting the Naive Bayes model
  Naive_Bayes_Model=naiveBayes(val_nbFormula, data=trainData)
  #What does the model say? Print the model summary
  Naive_Bayes_Model
  
  #Plotting the tree of train
  #plot(trainTree_Rock, compress=TRUE, uniform=TRUE)
  #text(trainTree_Rock,use.n = T,all=T,cex=.7, pretty=0, xpd=TRUE, digits = 6)
  #prp(trainTree_Rock, extra=101)

  pred_nb <- predict(Naive_Bayes_Model, trainData)
  mConfusion <- table(trainData$Class,pred_nb)
  
  
  #print(mConfusion)
  #Test Accuracy of model
  acc <- (mConfusion[1,1]+mConfusion[2,2])/sum(mConfusion)
  #print("acc")
  #print(acc*100)
  
  #Compute error rate
  Err <- (mConfusion[1,2]+mConfusion[2,1])/sum(mConfusion)
  #print("err")
  #print(Err*100)
  
  accs <- rbind(accs,acc)
  errors <- rbind(errors,Err)
}

meanAcc <- mean(accs)
meanError <- mean(errors)
print("Acc mean: ")
print(meanAcc)
print("Err mean: ")
print(meanError)
```





References:

MUSIC GENRE CLASSIFICATION: A MULTILINEAR APPROACH
http://www.mirlab.org/conference_papers/international_conference/ISMIR%202008/papers/ISMIR2008_181.pdf

Music Classification
http://www.nyu.edu/classes/bello/MIR_files/8-classification.pdf





